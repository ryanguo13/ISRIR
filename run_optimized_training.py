#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ä¼˜åŒ–è®­ç»ƒå¯åŠ¨è„šæœ¬
åŒ…å«è‡ªåŠ¨ç¯å¢ƒæ£€æµ‹ã€wandbé…ç½®å’Œè®­ç»ƒå¯åŠ¨
"""

import os
import sys
import subprocess
import json
import argparse


def check_environment():
    """æ£€æŸ¥è®­ç»ƒç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è®­ç»ƒç¯å¢ƒ...")
    
    # æ£€æŸ¥GPU
    try:
        import torch
        if torch.cuda.is_available():
            gpu_count = torch.cuda.device_count()
            current_gpu = torch.cuda.current_device()
            gpu_name = torch.cuda.get_device_name(current_gpu)
            gpu_memory = torch.cuda.get_device_properties(current_gpu).total_memory / 1024**3
            print(f"âœ… GPUå¯ç”¨: {gpu_name} ({gpu_memory:.1f}GB)")
            print(f"   å¯ç”¨GPUæ•°é‡: {gpu_count}")
            
            # æ¸…ç†GPUç¼“å­˜
            torch.cuda.empty_cache()
        else:
            print("âš ï¸  æœªæ£€æµ‹åˆ°GPUï¼Œå°†ä½¿ç”¨CPUè®­ç»ƒï¼ˆé€Ÿåº¦è¾ƒæ…¢ï¼‰")
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False
    
    # æ£€æŸ¥å¿…è¦çš„ä¾èµ–
    required_packages = ['wandb', 'numpy', 'matplotlib', 'seaborn', 'tqdm', 'tensorboardX']
    missing_packages = []
    
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}")
        except ImportError:
            missing_packages.append(package)
            print(f"âŒ {package} æœªå®‰è£…")
    
    if missing_packages:
        print(f"\nè¯·å®‰è£…ç¼ºå¤±çš„åŒ…: pip install {' '.join(missing_packages)}")
        return False
    
    return True


def setup_wandb():
    """è®¾ç½®wandb"""
    print("\nğŸ”§ è®¾ç½®Wandb...")
    
    try:
        import wandb
        
        # æ£€æŸ¥æ˜¯å¦å·²ç™»å½•
        if wandb.api.api_key is None:
            print("è¯·å…ˆç™»å½•wandb:")
            print("1. è®¿é—® https://wandb.ai/")
            print("2. æ³¨å†Œ/ç™»å½•è´¦æˆ·")
            print("3. å¤åˆ¶API key")
            print("4. è¿è¡Œ: wandb login")
            
            api_key = input("æˆ–è€…ç›´æ¥åœ¨è¿™é‡Œè¾“å…¥API key (ç•™ç©ºè·³è¿‡): ").strip()
            if api_key:
                wandb.login(key=api_key)
                print("âœ… Wandbç™»å½•æˆåŠŸ")
            else:
                print("âš ï¸  è·³è¿‡wandbç™»å½•ï¼Œå°†åœ¨ç¦»çº¿æ¨¡å¼è¿è¡Œ")
                os.environ['WANDB_MODE'] = 'offline'
        else:
            print("âœ… Wandbå·²ç™»å½•")
            
    except ImportError:
        print("âŒ Wandbæœªå®‰è£…")
        return False
    
    return True


def optimize_config(config_path):
    """æ ¹æ®ç³»ç»Ÿé…ç½®ä¼˜åŒ–è®­ç»ƒå‚æ•°"""
    print(f"\nâš™ï¸  ä¼˜åŒ–é…ç½®æ–‡ä»¶: {config_path}")
    
    try:
        import torch
        
        with open(config_path, 'r') as f:
            config = json.load(f)
            # config['datasets']['train']['batch_size'] = 8
            # config['datasets']['train']['num_workers'] = 12

        # # æ ¹æ®GPUå†…å­˜è°ƒæ•´batch size
        # if torch.cuda.is_available():
        #     gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            
        #     if gpu_memory >= 16:
        #         config['datasets']['train']['batch_size'] = 12
        #         config['datasets']['train']['num_workers'] = 16
        #         print(f"âœ… é«˜ç«¯GPUæ£€æµ‹ ({gpu_memory:.1f}GB)ï¼Œbatch_sizeè®¾ç½®ä¸º12")
        #     elif gpu_memory >= 8:
        #         print(f"âœ… ä¸­ç«¯GPUæ£€æµ‹ ({gpu_memory:.1f}GB)ï¼Œbatch_sizeè®¾ç½®ä¸º8")
        #     else:
        #         config['datasets']['train']['batch_size'] = 4
        #         config['datasets']['train']['num_workers'] = 8
        #         print(f"âœ… ä½ç«¯GPUæ£€æµ‹ ({gpu_memory:.1f}GB)ï¼Œbatch_sizeè®¾ç½®ä¸º4")
        # else:
        #     config['datasets']['train']['batch_size'] = 2
        #     config['datasets']['train']['num_workers'] = 4
        #     print("âš ï¸  CPUæ¨¡å¼ï¼Œbatch_sizeè®¾ç½®ä¸º2")
        
        # æ£€æŸ¥æ•°æ®é›†è·¯å¾„
        train_dataroot = config['datasets']['train']['dataroot']
        val_dataroot = config['datasets']['val']['dataroot']
        
        if not os.path.exists(train_dataroot):
            print(f"âš ï¸  è®­ç»ƒæ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {train_dataroot}")
            print("è¯·ç¡®ä¿æ•°æ®é›†å·²æ­£ç¡®ä¸‹è½½å’Œè§£å‹")
        
        if not os.path.exists(val_dataroot):
            print(f"âš ï¸  éªŒè¯æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨: {val_dataroot}")
            print("è¯·ç¡®ä¿æ•°æ®é›†å·²æ­£ç¡®ä¸‹è½½å’Œè§£å‹")
        
        # ä¿å­˜ä¼˜åŒ–åçš„é…ç½®
        # optimized_config_path = config_path.replace('.json', '_auto_optimized.json')
        # with open(optimized_config_path, 'w') as f:
        #     json.dump(config, f, indent=2)
        
        # print(f"âœ… ä¼˜åŒ–é…ç½®ä¿å­˜åˆ°: {optimized_config_path}")
        return config_path
        
    except Exception as e:
        print(f"âŒ é…ç½®ä¼˜åŒ–å¤±è´¥: {e}")
        return config_path


def create_directories():
    """åˆ›å»ºå¿…è¦çš„ç›®å½•"""
    base_dir = "F:/SR3_training_result"
    directories = [
        'logs', 'tb_logger', 'results', 'checkpoint', 'param_outputs'
    ]
    
    # åˆ›å»ºåŸºç¡€ç›®å½•
    os.makedirs(base_dir, exist_ok=True)
    
    # åˆ›å»ºå­ç›®å½•
    for dir_name in directories:
        full_path = os.path.join(base_dir, dir_name)
        os.makedirs(full_path, exist_ok=True)
    
    print("âœ… åˆ›å»ºè¾“å‡ºç›®å½•å®Œæˆ")


def main():
    parser = argparse.ArgumentParser(description='ä¼˜åŒ–è®­ç»ƒå¯åŠ¨è„šæœ¬')
    parser.add_argument('--config', '-c', type=str, 
                       default='config/517lc_optimized.json',
                       help='é…ç½®æ–‡ä»¶è·¯å¾„')
    parser.add_argument('--resume', '-r', type=str, default=None,
                       help='æ¢å¤è®­ç»ƒçš„checkpointè·¯å¾„')
    parser.add_argument('--no-wandb', action='store_true',
                       help='ç¦ç”¨wandbæ—¥å¿—')
    parser.add_argument('--dry-run', action='store_true',
                       help='ä»…æ£€æŸ¥ç¯å¢ƒï¼Œä¸å¼€å§‹è®­ç»ƒ')
    
    args = parser.parse_args()
    
    print("ğŸš€ å¼€å§‹ä¼˜åŒ–è®­ç»ƒé…ç½®...")
    print("=" * 60)
    
    # ç¯å¢ƒæ£€æŸ¥
    if not check_environment():
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·å®‰è£…å¿…è¦ä¾èµ–åé‡è¯•")
        sys.exit(1)
    
    # è®¾ç½®wandb
    if not args.no_wandb:
        if not setup_wandb():
            print("\nâš ï¸  Wandbè®¾ç½®å¤±è´¥ï¼Œå°†ç¦ç”¨wandbæ—¥å¿—")
            args.no_wandb = True
    
    # åˆ›å»ºç›®å½•
    create_directories()
    
    # ä¼˜åŒ–é…ç½®
    optimized_config = optimize_config(args.config)
    
    if args.dry_run:
        print("\nâœ… ç¯å¢ƒæ£€æŸ¥å®Œæˆ (dry-runæ¨¡å¼)")
        return
    
    # æ„å»ºè®­ç»ƒå‘½ä»¤
    cmd = [
        sys.executable, 'sr_optimized.py',
        '--config', optimized_config,
        '--phase', 'train'
    ]
    
    if not args.no_wandb:
        cmd.extend(['--enable_wandb', '--log_wandb_ckpt', '--log_eval'])
    
    if args.resume:
        # ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„resumeè·¯å¾„
        with open(optimized_config, 'r') as f:
            config = json.load(f)
        config['path']['resume_state'] = args.resume
        with open(optimized_config, 'w') as f:
            json.dump(config, f, indent=2)
        print(f"âœ… è®¾ç½®æ¢å¤è®­ç»ƒè·¯å¾„: {args.resume}")
    
    print("\nğŸš€ å¼€å§‹è®­ç»ƒ...")
    print("å‘½ä»¤:", ' '.join(cmd))
    print("=" * 60)
    
    # å¯åŠ¨è®­ç»ƒ
    try:
        subprocess.run(cmd, check=True)
        print("\nğŸ‰ è®­ç»ƒå®Œæˆ!")
    except subprocess.CalledProcessError as e:
        print(f"\nâŒ è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        sys.exit(1)
    except KeyboardInterrupt:
        print("\nâš ï¸  è®­ç»ƒè¢«ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)


if __name__ == "__main__":
    main() 